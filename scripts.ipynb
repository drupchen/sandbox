{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordancer. (outputs raw and xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = '''ཉེ་ཉོན་ཉི་ཤུ་ལས། \n",
    "ཁྲོ་བ་ནི་ཁོང་ཁྲོ་འཕེལ་ཏེ་བརྡེག་པ་སོགས་གནོད་པ་དངོས་སུ་ཤོམ་པར་བྱེད་པའོ། །\n",
    "འཁོན་དུ་འཛིན་པ་ནི་ཁོང་ཁྲོ་བའི་ཆར་གཏོགས་པ་གནོད་པའི་བསམ་པ་རྒྱུན་མི་གཏོང་ཞིང་མི་བཟོད་པར་བྱེད་པའོ། །\n",
    "འཚིག་པ་ནི་ཁྲོ་བ་དང་འཁོན་འཛིན་གྱི་རྒྱུ་ལས་མི་བཟོད་པར་ཚིག་རྩུབ་སྨྲ་བར་བྱེད་པའོ། །\n",
    "རྣམ་པར་འཚེ་བ་ནི་ཁོང་ཁྲོའི་ཆར་གཏོགས་པ། སྙིང་བརྩེ་བ་མེད་པར་རྣམ་པར་མཐོ་བཙམ་པའི་ལས་ཅན་ནོ། །'''\n",
    "\n",
    "plain_conc = []\n",
    "xml_entries = []\n",
    "# lines : cut the file in units separated by spaces\n",
    "mot = \"འདུལ་བ་\"\n",
    "left = 5\n",
    "right = 5\n",
    "\n",
    "occur_num = 1\n",
    "for line_number, line in enumerate(input_file):\n",
    "    if mot in line:\n",
    "        # find the positions of the occurences\n",
    "        syllabled = joinedword_list(mot, line)\n",
    "        positions = []\n",
    "        for syl_num, syl in enumerate(syllabled):\n",
    "            stripped_syl = syl.strip(\"།\")\n",
    "            if mot == stripped_syl:\n",
    "                positions.append(syl_num)\n",
    "                \n",
    "        # establishes right and left context\n",
    "        for pos in positions:\n",
    "            middle = syllabled[pos]\n",
    "            \n",
    "            context_left = \"\"\n",
    "            if len(syllabled[0:pos]) <= left:\n",
    "                if len(syllabled[0:pos]) == 0:\n",
    "                    context_left = \"\"\n",
    "                else:\n",
    "                    context_left = \"\".join(syllabled[0:pos])\n",
    "            else:\n",
    "                context_left = \"\".join(syllabled[pos-9:pos])\n",
    "                \n",
    "            context_right = \"\"\n",
    "            if len(syllabled[pos+1:]) <= right:\n",
    "                if len(syllabled[pos+1:]) == 0:\n",
    "                    context_right = \"\"\n",
    "                else:\n",
    "                    context_right = \"\".join(syllabled[pos+1:])\n",
    "            else:\n",
    "                context_right = \"\".join(syllabled[pos+1:pos+1+right])\n",
    "            \n",
    "            plain_conc.append(str(line_number+1)+\"\\t\"+context_left+\" -\"+str(occur_num)+\"|\"+middle+\"|- \"+context_right)\n",
    "            #print(str(line_number+1)+\"\\t\"+context_left+\" -\"+str(occur_num)+\"|\"+middle+\"|- \"+context_right)  \n",
    "            # xml entries for the concordancer\n",
    "            entry_indent = \"\\n\\t\"\n",
    "            parts_indent = \"\\n\\t\\t\"\n",
    "            xml_entries.append(entry_indent+\"<entry number=\\\"\"+str(occur_num)+\"\\\" line=\\\"\"+str(line_number+1)+\"\\\">\"+parts_indent+\"<left>\"+context_left+\"</left>\"+parts_indent+\"<middle>\"+middle+\"</middle>\"+parts_indent+\"<right>\"+context_right+\"</right>\"+entry_indent+\"</entry>\")\n",
    "            occur_num = occur_num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for p in plain_conc:\n",
    "    print(p)\n",
    "print()\n",
    "for x in xml_entries:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordancer demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yaml import load, dump\n",
    "import codecs\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unknown = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parts = load(codecs.open('syllables_dict.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('syllables_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(parts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('syllables_dict.pickle', 'rb') as f:\n",
    "    parts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"གནས་ལུགས་འདི་ལྟར་ལ་སོང་ད་ཆ་ཚོགས་ཆེན་ནས་ཁྱབ་བསྒྲགས་བྱ་རྒྱུར་ཡང་སྙིང་རྗེ་བྲལ་ཞིང་མི་སྤྱོད་ལས་འདས་པ་རབས་ཀྱི་སྤྱོད་ཚུལ་བཅས་ཏེ་མི་མང་གི་འདོད་པ་ནི་གཞུང་གི་དབང་ཆའི་གཞི་རྩར་འཛིན་དགོས་པ་ཡིན་ཞིང\"\n",
    "text = text.split('་')\n",
    "for num, t in enumerate(text):\n",
    "    if t in parts.keys():\n",
    "        if parts[text[num]]['mzh'] == 'པ' and parts[text[num+1]]['y1'] == 'ུ':\n",
    "            print(text[num]+'་'+text[num+1]+'་''་'+text[num+2])\n",
    "    else:\n",
    "        unknown.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sa_gc = 0\n",
    "for t in text:\n",
    "    if t in parts.keys():\n",
    "        if parts[t]['gc'] == 'ས':\n",
    "            sa_gc = sa_gc+1\n",
    "print(sa_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'ཞིང' in parts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dreldra = []\n",
    "jedra = []\n",
    "jungkhung = [[\"ཏུ\", [\"ག\", \"བ\"]]]\n",
    "ladon = [[\"སུ\", [\"ས\"]], [\"ཏུ\", [\"ག\", \"བ\"]],[\"རུ\", [\"འ\"]], [\"དུ\", [\"ང\", \"ད\", \"ན\", \"མ\", \"ར\", \"ལ\"]]]\n",
    "all_particles = [dreldra, jedra, jungkhung, ladon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['མ་ཏུ', 'བདག་དུ', 'ཁྲིམས་དུ']\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total : 0\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllable ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_sylSignature(syl_dict):\n",
    "    \"\"\"\n",
    "    The function creates the signature of a given syllable.\n",
    "    The structure is as follows : \n",
    "    \n",
    "    99[000]    [00]   [00]     [00]    [0]    [00]    [00]     [00]    [00]     [00]    [00]\n",
    "    99[mingzhi][gocan][ngonjug][dogcan][wazur][yang_1][jejug_1][yang_2][jejug_2][yang_3][yangjug]\n",
    "    \n",
    "    Each signature starts with 99, in order to recognize the start of a syllable and because the zeros at the beginning of integers aren't taken into account by python.\n",
    "    Each following position is made of two digits.\n",
    "    \n",
    "    The mingzhi's third digit serves to differenciate normal letters (0) and those below a gocan (1).  \n",
    "    It also serves to put syllables with a gocan after those without.    \n",
    "    \"\"\"\n",
    "    ngj = {\"\": \"00\", \"ག\" : \"01\", \"ད\" : \"02\", \"བ\" : \"03\", \"མ\" : \"04\", \"འ\" : \"05\"}\n",
    "    gc  = {\"\" : \"00\", \"ར\" : \"01\", \"ལ\" : \"02\", \"ས\" : \"03\"}\n",
    "    mzh = {\"ཀ\" : \"01\", \"ཁ\" : \"02\", \"ག\" : \"03\", \"ང\" : \"04\", \"ཅ\" : \"05\",  \"ཆ\" : \"06\", \"ཇ\" : \"07\", \"ཉ\" : \"08\", \"ཏ\" : \"09\",\"ཐ\" : \"10\", \"ད\" : \"11\", \"ན\" : \"12\", \"པ\" : \"13\", \"ཕ\" : \"14\", \"བ\" : \"15\", \"མ\" : \"16\", \"ཙ\" : \"17\", \"ཚ\" : \"18\", \"ཛ\" : \"19\", \"ཝ\" : \"20\", \"ཞ\" : \"21\", \"ཟ\" : \"22\", \"འ\" : \"23\", \"ཡ\" : \"24\", \"ར\" : \"25\", \"ལ\" : \"26\", \"ཤ\" : \"27\", \"ས\" : \"28\", \"ཧ\" : \"29\", \"ཨ\" : \"30\"}\n",
    "    dc  = {\"\" : \"00\", \"ཡ\" : \"01\", \"ར\" : \"02\", \"ལ\" : \"03\"}\n",
    "    y1  = {\"\" : \"00\", \"ི\" : \"01\", \"ུ\" : \"02\", \"ེ\" : \"03\", \"ོ\" : \"04\"}\n",
    "    jj1 = {\"\" : \"00\", \"ག\" : \"01\", \"ང\" : \"02\", \"ད\" : \"03\", \"ན\" : \"04\", \"བ\" : \"05\", \"མ\" : \"06\", \"འ\" : \"07\", \"ར\" : \"08\", \"ལ\" : \"09\", \"ས\" : \"10\"}\n",
    "    y2  = y1\n",
    "    jj2 = jj1\n",
    "    y3  = y1\n",
    "    yj  = {\"\" : \"00\", \"ད\" : \"01\", \"ས\" : \"02\"}\n",
    "    wz  = {\"\" : \"0\", \"ཝ\" : \"1\"}\n",
    "    \n",
    "    pos1 = mzh[syl_dict[\"mzh\"]]\n",
    "    pos2 = gc[syl_dict[\"gc\"]]\n",
    "    pos3 = ngj[syl_dict[\"ngj\"]]\n",
    "    pos4 = dc[syl_dict[\"dc\"]]\n",
    "    pos5 = wz[syl_dict[\"wz\"]]\n",
    "    pos6 = y1[syl_dict[\"y1\"]]\n",
    "    pos7 = jj1[syl_dict[\"jj1\"]]\n",
    "    pos8 = y2[syl_dict[\"y2\"]]\n",
    "    pos9 = jj2[syl_dict[\"jj2\"]]\n",
    "    pos10 = y3[syl_dict[\"y3\"]]\n",
    "    pos11 = yj[syl_dict[\"yj\"]]\n",
    "\n",
    "    \n",
    "    # 3rd mingzhi position : with or without gocan\n",
    "    if pos2 == \"00\":\n",
    "        pos1 = pos1+\"0\"\n",
    "    else:\n",
    "        pos1 = pos1+\"1\"\n",
    "    \n",
    "    return int(\"99\"+pos1+pos2+pos3+pos4+pos5+pos6+pos7+pos8+pos9+pos10+pos11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sylFromSignature(signature):\n",
    "    \"\"\"\n",
    "    The function for regenerating the syllable\n",
    "    from the signature.\n",
    "    its output is a tuple with the syllable and \n",
    "    a dict with its elements.\n",
    "    \"\"\"\n",
    "    ngj = {\"00\" : \"\", \"01\" : \"ག\", \"02\" : \"ད\", \"03\" : \"བ\", \"04\" : \"མ\", \"05\" : \"འ\"}\n",
    "    gc = {\"00\" : \"\", \"01\" : \"ར\", \"02\" : \"ལ\", \"03\" : \"ས\"}\n",
    "    mzh = {\"000\" : \"\", \"010\" : \"ཀ\", \"011\" : \"ྐ\", \"020\" : \"ཁ\", \"030\" : \"ག\", \"031\" : \"ྒ\", \"040\" : \"ང\", \"041\" : \"ྔ\", \"050\" : \"ཅ\", \"051\" : \"ྕ\", \"060\" : \"ཆ\", \"070\" : \"ཇ\", \"071\" : \"ྗ\", \"080\" : \"ཉ\", \"081\" : \"ྙ\", \"090\" : \"ཏ\",\"091\" : \"ྟ\", \"100\" : \"ཐ\", \"110\" : \"ད\", \"111\" : \"ྡ\", \"120\" : \"ན\", \"121\" : \"ྣ\", \"130\" : \"པ\", \"131\" : \"ྤ\", \"140\" : \"ཕ\", \"150\" : \"བ\", \"151\" : \"ྦ\", \"160\" : \"མ\", \"161\" : \"ྨ\", \"170\" : \"ཙ\", \"171\" : \"ྩ\", \"180\" : \"ཚ\", \"190\" : \"ཛ\", \"191\" : \"ྫ\", \"200\" : \"ཝ\", \"210\" : \"ཞ\", \"220\" : \"ཟ\", \"230\" : \"འ\", \"240\" : \"ཡ\", \"250\" : \"ར\", \"260\" : \"ལ\", \"270\" : \"ཤ\", \"280\" : \"ས\", \"290\" : \"ཧ\", \"291\" : \"ྷ\", \"300\" : \"ཨ\"}\n",
    "    dc = {\"00\" : \"\", \"01\" : \"ྱ\", \"02\" : \"ྲ\", \"03\" : \"ླ\"}\n",
    "    y = {\"00\" : \"\", \"01\" : \"ི\", \"02\" : \"ུ\", \"03\" : \"ེ\", \"04\" : \"ོ\"}\n",
    "    jj = {\"00\" : \"\", \"01\" : \"ག\", \"02\" : \"ང\", \"03\" : \"ད\", \"04\" : \"ན\", \"05\" : \"བ\", \"06\" : \"མ\", \"07\" : \"འ\", \"08\" : \"ར\", \"09\" : \"ལ\", \"10\" : \"ས\"}\n",
    "    yj = {\"00\" : \"\", \"01\" : \"ད\", \"02\" : \"ས\"}\n",
    "    wz  = {\"0\" : \"\", \"1\" : \"ྭ\"}\n",
    "\n",
    "    signature = str(signature)\n",
    "    pos1 = mzh[signature[2:5]]\n",
    "    pos2 = gc[signature[5:7]]\n",
    "    pos3 = ngj[signature[7:9]]\n",
    "    pos4 = dc[signature[9:11]]\n",
    "    pos5= wz[signature[23:24]]\n",
    "    pos6 = y[signature[11:13]]\n",
    "    pos7 = jj[signature[13:15]]\n",
    "    pos8 = yj[signature[15:17]]\n",
    "    pos9 = jj[signature[17:19]]\n",
    "    pos10 = y[signature[19:21]]\n",
    "    pos11= yj[signature[21:23]]\n",
    "\n",
    "    \n",
    "    norlet = {\"\": \"\", \"ྐ\" : \"ཀ\", \"ྒ\" : \"ག\", \"ྔ\" : \"ང\", \"ྕ\" : \"ཅ\", \"ྗ\" : \"ཇ\", \"ྙ\" : \"ཉ\", \"ྟ\" : \"ཏ\", \"ྡ\" : \"ད\", \"ྣ\" : \"ན\", \"ྤ\" : \"པ\", \"ྦ\" : \"བ\", \"ྨ\" : \"མ\", \"ྩ\" : \"ཙ\", \"ྫ\" : \"ཛ\", \"ྭ\" : \"ཝ\", \"ྱ\" : \"ཡ\", \"ྲ\" : \"ར\", \"ླ\" : \"ལ\", \"ྷ\" : \"ཧ\"}\n",
    "    syl_dict = {\"ngj\" : pos3, \"gc\" : pos2, \"mzh\" : norlet[pos1], \"dc\" : norlet[pos4], \"wz\" : norlet[pos5], \"y1\" : pos6, \"jj1\" : pos7, \"y2\" : pos8, \"jj2\" : pos9, \"y3\" : pos10, \"yj\" : pos11}\n",
    "    syllable = pos3+pos2+pos1+pos4+pos5+pos6+pos7+pos8+pos9+pos10+pos11+\"་\"\n",
    "    return syllable, syl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99031030302020500010\n",
      "('བསྒྲུབས་', {'dogcan': 'ར', 'mingzhi': 'ག', 'yang_1': 'ུ', 'jejug': 'བ', 'yangjug': 'ས', 'wazur': '', 'yang_2': '', 'ngonjug': 'བ', 'gocan': 'ས'})\n"
     ]
    }
   ],
   "source": [
    "currentSyl = {'jj1': '', 'y1': 'ི', 'wz': '', 'ngj': '', 'yj': '', 'y2': '', 'gc': '', 'mzh': 'ཀ', 'jj2': '', 'y3': '', 'dc': ''}\n",
    "print(create_sylSignature(currentSyl))\n",
    "currentSyl = {'jj1': '', 'y1': '', 'wz': '', 'ngj': '', 'yj': '', 'y2': '', 'gc': 'ས', 'mzh': 'ཀ', 'jj2': '', 'y3': '', 'dc': ''}\n",
    "print(create_sylSignature(currentSyl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig = 990110300000000000000000\n",
    "\n",
    "print(sylFromSignature(sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count syllables and letters in a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python3 syl_letter_count.py file-to-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/a-couple-must-par_11.txt'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-18132d70df4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#text = codecs.open(sys.argv[1], \"r\", \"utf8\").readlines() # line for the command line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./input/a-couple-must-par_11.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# line to uncomment in ipython\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/drupchen/anaconda3/lib/python3.4/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/a-couple-must-par_11.txt'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#text = codecs.open(sys.argv[1], \"r\", \"utf8\").readlines() # line for the command line \n",
    "text = codecs.open(\"./input/a-couple-must-par_11.txt\", \"r\", \"utf8\").readlines() # line to uncomment in ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c702653c9a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcount_syl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcount_letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[། {}]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"་\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"་+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"་\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "count_syl = {}\n",
    "count_letter = {}\n",
    "for line in text:\n",
    "    line = re.sub(\"[། {}]\", \"་\", line.strip())\n",
    "    line = re.sub(r\"་+\", \"་\", line)\n",
    "    syllables = line.split(\"་\")\n",
    "    for syl in syllables:\n",
    "        if syl != \"\":\n",
    "            if syl in count_syl:\n",
    "                count_syl[syl] = count_syl[syl]+1\n",
    "            else:\n",
    "                count_syl[syl] = 1\n",
    "            for letter in syl:\n",
    "                if letter in count_letter:\n",
    "                    count_letter[letter] = count_letter[letter]+1\n",
    "                else:\n",
    "                    count_letter[letter] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syllables = []\n",
    "letters = []\n",
    "\n",
    "for syl in count_syl:\n",
    "    syllables.append((count_syl[syl], syl))\n",
    "syllables = sorted(syllables, reverse=True)\n",
    "\n",
    "for letter in count_letter:\n",
    "    letters.append((count_letter[letter], letter))\n",
    "letters = sorted(letters, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep1 = \"_\"\n",
    "sep2 = \" \"\n",
    "for syl in syllables:\n",
    "    print(str(syl[0])+sep1+syl[1], end= sep2)\n",
    "print(\"\\n\")\n",
    "\n",
    "for l in letters:\n",
    "    print(str(l[0])+sep1+l[1], end= sep2)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output1 = codecs.open(\"a-couple-must-par_11_syl-count.txt\", \"w\", \"utf8\") # ipython\n",
    "#output1 = codecs.open(sys.argv[1].split(\".\")[0]+\"_syl-count.txt\", \"w\", \"utf8\") # command line\n",
    "for syl in syllables:\n",
    "    output1.write(str(syl[0])+sep1+syl[1]+\"\\n\")\n",
    "output1.close()\n",
    "\n",
    "output2 = codecs.open(\"a-couple-must-par_11_letter-count.txt\", \"w\", \"utf8\") # ipython\n",
    "#output2 = codecs.open(sys.argv[1].split(\".\")[0]+\"_letter-count.txt\", \"w\", \"utf8\") # command line\n",
    "for l in letters:\n",
    "    output2.write(str(l[0])+sep1+l[1]+\"\\n\")\n",
    "output2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = 13 # length of lines\n",
    "def presentation(liste, unit, per_occ):\n",
    "    sep = \"_\"\n",
    "    out = \"\"\n",
    "    total = 0\n",
    "    for elt in liste:\n",
    "        total = total + elt[0]\n",
    "    out += str(total)+unit+\"\\n\"\n",
    "    counter = 0\n",
    "    while len(liste)-counter > length:\n",
    "        for i in range(length):\n",
    "            occurences = liste[counter][0]\n",
    "            current = liste[counter][1]\n",
    "            if per_occ == \"percentage\":\n",
    "                percent = \"{:.1%}\".format(occurences/total)\n",
    "                out += str(current)+sep+str(percent)+\"\\t\"\n",
    "            if per_occ == \"occurences\":\n",
    "                out += str(current)+sep+str(occurences)+\"\\t\"\n",
    "            counter = counter +1\n",
    "        out += \"\\n\"\n",
    "    for i in range(len(liste)-counter):\n",
    "        occurences = liste[counter][0]\n",
    "        current = liste[counter][1]\n",
    "        if per_occ == \"percentage\":\n",
    "            percent = \"{:.1%}\".format(occurences/total)\n",
    "            out += str(current)+sep+str(percent)+\"\\t\"\n",
    "        if per_occ == \"occurences\":\n",
    "            out += str(current)+sep+str(occurences)+\"\\t\"\n",
    "        counter = counter +1\n",
    "    out += \"\\n\\n\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ordered_list(dictionary):\n",
    "    \"\"\"\n",
    "    takes a dictionary with \n",
    "    \"\"\"\n",
    "    liste = []\n",
    "    for entry in dictionary:\n",
    "        liste.append((dictionary[entry], entry))\n",
    "    liste = sorted(liste, reverse=True)\n",
    "    return liste\n",
    "#print(ordered_list({\"a\": 3, \"b\" : 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_syl = {}\n",
    "all_let = {}\n",
    "os.chdir(\"./input\")\n",
    "for File in os.listdir(\".\"):\n",
    "    print(File)\n",
    "    filename = File.split(\".\")[0]\n",
    "    text = codecs.open(File, \"r\", \"utf8\").readlines()\n",
    "    count_syl = {}\n",
    "    count_letter = {}\n",
    "    for line in text:\n",
    "        line = re.sub(\"[། {}]\", \"་\", line.strip())\n",
    "        line = re.sub(r\"་+\", \"་\", line)\n",
    "        syllables = line.split(\"་\")\n",
    "        for syl in syllables:\n",
    "            if syl != \"\":\n",
    "                # counting for each file\n",
    "                if syl in count_syl:\n",
    "                    count_syl[syl] = count_syl[syl]+1\n",
    "                else:\n",
    "                    count_syl[syl] = 1\n",
    "                for letter in syl:\n",
    "                    if letter in count_letter:\n",
    "                        count_letter[letter] = count_letter[letter]+1\n",
    "                    else:\n",
    "                        count_letter[letter] = 1\n",
    "                # counting for all files\n",
    "                if syl in all_syl:\n",
    "                    all_syl[syl] = all_syl[syl]+1\n",
    "                else:\n",
    "                    all_syl[syl] = 1\n",
    "                for letter in syl:\n",
    "                    if letter in all_let:\n",
    "                        all_let[letter] = all_let[letter]+1\n",
    "                    else:\n",
    "                        all_let[letter] = 1\n",
    "    \n",
    "    os.chdir(\"../output\")\n",
    "    output1 = codecs.open(\"count_\"+filename+\".txt\", \"w\", \"utf8\")\n",
    "    for elt in [\"percentage\", \"occurences\"]:\n",
    "        output1.write(presentation(ordered_list(count_syl), \" syllables\", elt))\n",
    "    for elt in [\"percentage\", \"occurences\"]:\n",
    "        output1.write(presentation(ordered_list(count_letter), \" letters\", elt))\n",
    "    output1.close()\n",
    "    os.chdir(\"../input\")\n",
    "os.chdir(\"../\")\n",
    "os.chdir(\"./output\")\n",
    "\n",
    "output1 = codecs.open(\"total-count_\"+filename+\".txt\", \"w\", \"utf8\")\n",
    "for elt in [\"percentage\", \"occurences\"]:\n",
    "    output1.write(presentation(ordered_list(all_syl), \" syllables\", elt))\n",
    "for elt in [\"percentage\", \"occurences\"]:\n",
    "    output1.write(presentation(ordered_list(all_let), \" letters\", elt))\n",
    "output1.close()\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = 13 # length of lines\n",
    "def presentation(liste, unit, per_occ):\n",
    "    sep = \"_\"\n",
    "    out = \"\"\n",
    "    total = 0\n",
    "    for elt in liste:\n",
    "        total = total + elt[0]\n",
    "    out += str(total)+unit+\"\\n\"\n",
    "    counter = 0\n",
    "    while len(liste)-counter > length:\n",
    "        for i in range(length):\n",
    "            occurences = liste[counter][0]\n",
    "            current = liste[counter][1]\n",
    "            if per_occ == \"percentage\":\n",
    "                percent = \"{:.1%}\".format(occurences/total)\n",
    "                out += str(current)+sep+str(percent)+\"\\t\"\n",
    "            if per_occ == \"occurences\":\n",
    "                out += str(current)+sep+str(occurences)+\"\\t\"\n",
    "            counter = counter +1\n",
    "        out += \"\\n\"\n",
    "    for i in range(len(liste)-counter):\n",
    "        occurences = liste[counter][0]\n",
    "        current = liste[counter][1]\n",
    "        if per_occ == \"percentage\":\n",
    "            percent = \"{:.1%}\".format(occurences/total)\n",
    "            out += str(current)+sep+str(percent)+\"\\t\"\n",
    "        if per_occ == \"occurences\":\n",
    "            out += str(current)+sep+str(occurences)+\"\\t\"\n",
    "        counter = counter +1\n",
    "    out += \"\\n\\n\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def len_list_sort(super_list):\n",
    "    temp = []\n",
    "    out = []\n",
    "    for liste in super_list:\n",
    "        temp.append((len(liste), liste))\n",
    "    temp = sorted(temp, reverse=True)\n",
    "    for t in temp:\n",
    "        out.append(t[1])\n",
    "    return len(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_presentation(tuple_list):\n",
    "    total = 0\n",
    "    for elt in tuple_list:\n",
    "        total = total + elt[0]\n",
    "    entries = [\"Total Syllables\"]\n",
    "    occurences = [str(total)]\n",
    "    percentages = [\"100%\"]\n",
    "    for t in tuple_list:\n",
    "        entries.append(t[1]+\"་\")\n",
    "        occurences.append(str(t[0]))\n",
    "        percentages.append(\"{:.1%}\".format(t[0]/total))\n",
    "    return [entries,percentages, occurences]\n",
    "    #print(entries, occurences, percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_output(super_list):\n",
    "    \"\"\"\n",
    "    takes a list of lists and outputs a string where each column is \n",
    "    one on the second-level list.\n",
    "    requires len_list_sort()\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    longrow = len_list_sort(super_list)\n",
    "    cols = len(super_list)\n",
    "    for l in range(longrow):\n",
    "        for c in range(cols):\n",
    "            if l < len(super_list[c]):\n",
    "                out += super_list[c][l]+\"\\t\"\n",
    "            else:\n",
    "                out += \"\\t\"\n",
    "        out += \"\\n\"\n",
    "    return out\n",
    "#print(csv_output([[\"1\",\"5\",\"9\",\"13\"],[\"2\",\"6\",\"10\"],[\"3\",\"7\",\"11\",\"14\",\"15\",\"16\",\"23\"],[\"4\",\"8\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_syl = {}\n",
    "all_let = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./input\")\n",
    "for File in os.listdir(\".\"):\n",
    "    print(File)\n",
    "    filename = File.split(\".\")[0]\n",
    "    text = codecs.open(File, \"r\", \"utf8\").readlines()\n",
    "    count_syl = {}\n",
    "    count_letter = {}\n",
    "    for line in text:\n",
    "        line = re.sub(\"[། {}]\", \"་\", line.strip())\n",
    "        line = re.sub(r\"་+\", \"་\", line)\n",
    "        syllables = line.split(\"་\")\n",
    "        for syl in syllables:\n",
    "            if syl != \"\":\n",
    "                # counting for each file\n",
    "                if syl in count_syl:\n",
    "                    count_syl[syl] = count_syl[syl]+1\n",
    "                else:\n",
    "                    count_syl[syl] = 1\n",
    "                for letter in syl:\n",
    "                    if letter in count_letter:\n",
    "                        count_letter[letter] = count_letter[letter]+1\n",
    "                    else:\n",
    "                        count_letter[letter] = 1\n",
    "                # counting for all files\n",
    "                if syl in all_syl:\n",
    "                    all_syl[syl] = all_syl[syl]+1\n",
    "                else:\n",
    "                    all_syl[syl] = 1\n",
    "                for letter in syl:\n",
    "                    if letter in all_let:\n",
    "                        all_let[letter] = all_let[letter]+1\n",
    "                    else:\n",
    "                        all_let[letter] = 1\n",
    "    \n",
    "    os.chdir(\"../output\")\n",
    "    output1 = codecs.open(\"count_\"+filename+\".txt\", \"w\", \"utf8\")\n",
    "    for elt in [\"percentage\", \"occurences\"]:\n",
    "        output1.write(presentation(ordered_list(count_syl), \" syllables\", elt))\n",
    "    for elt in [\"percentage\", \"occurences\"]:\n",
    "        output1.write(presentation(ordered_list(count_letter), \" letters\", elt))\n",
    "    output1.close()\n",
    "    os.chdir(\"../input\")\n",
    "os.chdir(\"../\")\n",
    "os.chdir(\"./output\")\n",
    "\n",
    "output2 = codecs.open(\"total-count_\"+filename+\".csv\", \"w\", \"utf8\")\n",
    "output2.write(csv_output(csv_presentation(ordered_list(all_syl))+csv_presentation(ordered_list(all_let))))\n",
    "output2.close()\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : qqch qui détecte les malformations à partir de tsetan shabdrung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# No stack\n",
    "salje30 = [\"ཀ\", \"ཁ\", \"ག\", \"ང\", \"ཅ\", \"ཆ\", \"ཇ\", \"ཉ\", \"ཏ\", \"ཐ\", \"ད\", \"ན\", \"པ\", \"ཕ\", \"བ\", \"མ\", \"ཙ\", \"ཚ\", \"ཛ\", \"ཝ\", \"ཞ\", \"ཟ\", \"འ\", \"ཡ\", \"ར\", \"ལ\", \"ཤ\", \"ས\", \"ཧ\", \"ཨ\"]\n",
    "\n",
    "# 2 letters stack\n",
    "raGocan12 = [\"རྐ\", \"རྒ\", \"རྔ\", \"རྗ\", \"རྙ\", \"རྟ\", \"རྡ\", \"རྣ\", \"རྦ\", \"རྨ\", \"རྩ\", \"རྫ\"]\n",
    "laGocan10 = [\"ལྐ\", \"ལྒ\", \"ལྔ\", \"ལྕ\", \"ལྗ\", \"ལྟ\", \"ལྡ\", \"ལྤ\", \"ལྦ\", \"ལྷ\"]\n",
    "saGocan11 = [\"སྐ\", \"སྒ\", \"སྔ\", \"སྙ\", \"སྟ\", \"སྡ\", \"སྣ\", \"སྤ\", \"སྦ\", \"སྨ\", \"སྩ\"]\n",
    "\n",
    "yaDogcan9 = [\"ཀྱ\", \"ཁྱ\", \"གྱ\", \"པྱ\", \"ཕྱ\", \"བྱ\", \"མྱ\", \"དྱ\", \"ཧྱ\"] # ཡ་འདོགས་ཅན་བདུན་ལ་མི་འགལ་བ་གཉིས་མནན་པས་དགུ་ཡིན།\n",
    "raDogcan12 = [\"ཀྲ\", \"ཁྲ\", \"གྲ\", \"ཏྲ\", \"ཐྲ\",\"དྲ\", \"པྲ\", \"ཕྲ\", \"བྲ\", \"མྲ\", \"སྲ\", \"ཧྲ\"]\n",
    "laDogcan6 = [\"ཀླ\", \"གླ\", \"བླ\", \"ཟླ\", \"རླ\", \"སླ\"]\n",
    "\n",
    "# 3 letters stack\n",
    "yatagSumtseg8 = [\"རྐྱ\", \"རྒྱ\", \"རྨྱ\", \"སྐྱ\", \"སྒྱ\", \"སྤྱ\", \"སྦྱ\", \"སྨྱ\"]\n",
    "ratagSumtseg6 = [\"སྐྲ\", \"སྒྲ\", \"སྣྲ\", \"སྤྲ\", \"སྦྲ\", \"སྨྲ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gocan33 =  raGocan12 + laGocan10 + saGocan11\n",
    "dogcan27 = yaDogcan9 + raDogcan12 + laDogcan6 # འདོགས་ཅན་ཉེར་ལྔ་ལ་ཡ་འདོགས་ཅན་དམིགས་གསལ་གཉིས་མནན་པས་ཉེར་བདུན་ཡིན།\n",
    "sumtseg14 = yatagSumtseg8 + ratagSumtseg6 \n",
    "tsegYig74 = gocan33 + dogcan27 + sumtseg14 # གོང་གསལ་གཞིན་དོན་གཉིས་ལ་གཉིས་མནན་པས་དོན་བཞི་ཡིན།\n",
    "\n",
    "# Grand total\n",
    "kyangTsegDogKun = salje30 + tsegYig74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salje_parts = {\"ཀ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"\"}, \"ཁ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཁ\", \"dogcan\" : \"\"}, \"ག\" : {\"gocan\" : \"\", \"mingzhi\" : \"ག\", \"dogcan\" : \"\"}, \"ང\" : {\"gocan\" : \"\", \"mingzhi\" : \"ང\", \"dogcan\" : \"\"}, \"ཅ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཅ\", \"dogcan\" : \"\"}, \"ཆ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཆ\", \"dogcan\" : \"\"}, \"ཇ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཇ\", \"dogcan\" : \"\"}, \"ཉ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཉ\", \"dogcan\" : \"\"}, \"ཏ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཏ\", \"dogcan\" : \"\"}, \"ཐ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཐ\", \"dogcan\" : \"\"}, \"ད\" : {\"gocan\" : \"\", \"mingzhi\" : \"ད\", \"dogcan\" : \"\"}, \"ན\" : {\"gocan\" : \"\", \"mingzhi\" : \"ན\", \"dogcan\" : \"\"}, \"པ\" : {\"gocan\" : \"\", \"mingzhi\" : \"པ\", \"dogcan\" : \"\"}, \"ཕ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཕ\", \"dogcan\" : \"\"}, \"བ\" : {\"gocan\" : \"\", \"mingzhi\" : \"བ\", \"dogcan\" : \"\"}, \"མ\" : {\"gocan\" : \"\", \"mingzhi\" : \"མ\", \"dogcan\" : \"\"}, \"ཙ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཙ\", \"dogcan\" : \"\"}, \"ཚ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཚ\", \"dogcan\" : \"\"}, \"ཛ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཛ\", \"dogcan\" : \"\"}, \"ཝ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཝ\", \"dogcan\" : \"\"}, \"ཞ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཞ\", \"dogcan\" : \"\"}, \"ཟ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཟ\", \"dogcan\" : \"\"}, \"འ\" : {\"gocan\" : \"\", \"mingzhi\" : \"འ\", \"dogcan\" : \"\"}, \"ཡ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཡ\", \"dogcan\" : \"\"}, \"ར\" : {\"gocan\" : \"\", \"mingzhi\" : \"ར\", \"dogcan\" : \"\"}, \"ལ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ལ\", \"dogcan\" : \"\"}, \"ཤ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཤ\", \"dogcan\" : \"\"}, \"ས\" : {\"gocan\" : \"\", \"mingzhi\" : \"ས\", \"dogcan\" : \"\"}, \"ཧ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཧ\", \"dogcan\" : \"\"}, \"ཨ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཨ\", \"dogcan\" : \"\"}}\n",
    "ragocan_parts = {\"རྐ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"\"}, \"རྒ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ག\", \"dogcan\" : \"\"}, \"རྔ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ང\", \"dogcan\" : \"\"}, \"རྗ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཇ\", \"dogcan\" : \"\"}, \"རྙ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཉ\", \"dogcan\" : \"\"}, \"རྟ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཏ\", \"dogcan\" : \"\"}, \"རྡ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ད\", \"dogcan\" : \"\"}, \"རྣ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ན\", \"dogcan\" : \"\"}, \"རྦ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"བ\", \"dogcan\" : \"\"}, \"རྨ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"མ\", \"dogcan\" : \"\"}, \"རྩ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཙ\", \"dogcan\" : \"\"}, \"རྫ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཛ\", \"dogcan\" : \"\"}}\n",
    "lagocan_parts = {\"ལྐ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"\"}, \"ལྒ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ག\", \"dogcan\" : \"\"}, \"ལྔ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ང\", \"dogcan\" : \"\"}, \"ལྕ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ཅ\", \"dogcan\" : \"\"}, \"ལྗ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ཇ\", \"dogcan\" : \"\"}, \"ལྟ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ཏ\", \"dogcan\" : \"\"}, \"ལྡ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ད\", \"dogcan\" : \"\"}, \"ལྤ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"པ\", \"dogcan\" : \"\"}, \"ལྦ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"བ\", \"dogcan\" : \"\"}, \"ལྷ\" : {\"gocan\" : \"ལ\", \"mingzhi\" : \"ཧ\", \"dogcan\" : \"\"}}\n",
    "sagocan_parts = {\"སྐ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"\"}, \"སྒ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ག\", \"dogcan\" : \"\"}, \"སྔ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ང\", \"dogcan\" : \"\"}, \"སྙ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཉ\", \"dogcan\" : \"\"}, \"སྟ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཏ\", \"dogcan\" : \"\"}, \"སྡ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ད\", \"dogcan\" : \"\"}, \"སྣ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ན\", \"dogcan\" : \"\"}, \"སྤ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"པ\", \"dogcan\" : \"\"}, \"སྦ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"བ\", \"dogcan\" : \"\"}, \"སྨ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"མ\", \"dogcan\" : \"\"}, \"སྩ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཙ\", \"dogcan\" : \"\"}}\n",
    "yadogcan_parts = {\"ཀྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཀ\", \"dogcan\" : \"ཡ\"}, \"ཁྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཁ\", \"dogcan\" : \"ཡ\"}, \"གྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ག\", \"dogcan\" : \"ཡ\"}, \"པྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"པ\", \"dogcan\" : \"ཡ\"}, \"ཕྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཕ\", \"dogcan\" : \"ཡ\"}, \"བྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"བ\", \"dogcan\" : \"ཡ\"}, \"མྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"མ\", \"dogcan\" : \"ཡ\"}, \"དྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ད\", \"dogcan\" : \"ཡ\"}, \"ཧྱ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཧ\", \"dogcan\" : \"ཡ\"}}\n",
    "radogcan_parts = {\"gocan\" : \"\",\"ཀྲ\" : {\"gocan\" : \"\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"ར\"}, \"ཁྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཁ\", \"dogcan\" : \"ར\"}, \"གྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ག\", \"dogcan\" : \"ར\"}, \"ཏྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཏ\", \"dogcan\" : \"ར\"}, \"ཐྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཐ\", \"dogcan\" : \"ར\"}, \"དྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ད\", \"dogcan\" : \"ར\"}, \"པྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"པ\", \"dogcan\" : \"ར\"}, \"ཕྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཕ\", \"dogcan\" : \"ར\"}, \"བྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"བ\", \"dogcan\" : \"ར\"}, \"མྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"མ\", \"dogcan\" : \"ར\"}, \"སྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ས\", \"dogcan\" : \"ར\"}, \"ཧྲ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཧ\", \"dogcan\" : \"ར\"}}\n",
    "ladogcan_parts = {\"ཀླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཀ\", \"dogcan\" : \"ལ\"}, \"གླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ག\", \"dogcan\" : \"ལ\"}, \"བླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"བ\", \"dogcan\" : \"ལ\"}, \"ཟླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ཟ\", \"dogcan\" : \"ལ\"}, \"རླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ར\", \"dogcan\" : \"ལ\"}, \"སླ\" : {\"gocan\" : \"\",\"mingzhi\" : \"ས\", \"dogcan\" : \"ལ\"}}\n",
    "yatagSumtseg_parts = {\"རྐྱ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"ཡ\"}, \"རྒྱ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"ག\", \"dogcan\" : \"ཡ\"}, \"རྨྱ\" : {\"gocan\" : \"ར\", \"mingzhi\" : \"མ\", \"dogcan\" : \"ཡ\"}, \"སྐྱ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"ཡ\"}, \"སྒྱ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ག\", \"dogcan\" : \"ཡ\"}, \"སྤྱ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"པ\", \"dogcan\" : \"ཡ\"}, \"སྦྱ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"བ\", \"dogcan\" : \"ཡ\"}, \"སྨྱ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"མ\", \"dogcan\" : \"ཡ\"}}\n",
    "ratagSumtseg_parts = {\"སྐྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ཀ\", \"dogcan\" : \"ར\"}, \"སྒྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ག\", \"dogcan\" : \"ར\"}, \"སྣྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"ན\", \"dogcan\" : \"ར\"}, \"སྤྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"པ\", \"dogcan\" : \"ར\"}, \"སྦྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"བ\", \"dogcan\" : \"ར\"}, \"སྨྲ\" : {\"gocan\" : \"ས\", \"mingzhi\" : \"མ\", \"dogcan\" : \"ར\"}}\n",
    "all_parts_dict = {}\n",
    "for l in [salje_parts, ragocan_parts, lagocan_parts, sagocan_parts, yadogcan_parts, radogcan_parts, ladogcan_parts, yatagSumtseg_parts,ratagSumtseg_parts ]:\n",
    "    all_parts_dict.update(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gePhulKyangpa11 = [\"ཅ\", \"ཉ\", \"ཏ\", \"ད\", \"ན\", \"ཙ\", \"ཞ\", \"ཟ\", \"ཡ\", \"ཤ\", \"ས\"]\n",
    "\n",
    "dePhulKyangpa6 = [\"ཀ\", \"ག\", \"ང\", \"པ\", \"བ\", \"མ\"]\n",
    "dePhulDogcan10 = [\"ཀྱ\", \"ཀྲ\", \"གྱ\", \"གྲ\", \"པྱ\", \"པྲ\", \"བྱ\", \"བྲ\", \"མྱ\", \"མྲ\"]\n",
    "\n",
    "bePhulKyangpa10 = [\"ཀ\", \"ག\", \"ཅ\", \"ཏ\", \"ད\", \"ཙ\", \"ཞ\", \"ཟ\", \"ཤ\", \"ས\"]\n",
    "bePhulDogcan7 = [\"ཀྱ\", \"ཀྲ\", \"ཀླ\", \"གྱ\", \"ཟླ\", \"གླ\", \"གྲ\"]\n",
    "bePhulRaGocan11 = [\"རྐ\", \"རྒ\", \"རྔ\", \"རྗ\", \"རྙ\", \"རྟ\", \"རྔ\", \"རྣ\", \"རྩ\", \"རྫ\", \"རླ\"]\n",
    "bePhulLaGocan2 = [\"ལྟ\", \"ལྡ\"]\n",
    "bePhulSaGocan10 = [\"སྐ\", \"སྒ\", \"སྔ\", \"སྙ\", \"སྟ\", \"སྡ\", \"སྣ\", \"སྩ\", \"སྲ\", \"སླ\"]\n",
    "bePhulSumtseg6 = [\"རྐྱ\", \"རྒྱ\", \"སྐྱ\", \"སྐྲ\", \"སྒྱ\", \"སྒྲ\"]\n",
    "\n",
    "mePhulKyangpa11 = [\"ཁ\", \"ག\", \"ང\", \"ཆ\", \"ཇ\", \"ཉ\", \"ཐ\", \"ད\", \"ན\", \"ཚ\", \"ཛ\"]\n",
    "mePhulDogcan4 = [\"ཁྱ\", \"ཁྲ\", \"གྱ\", \"གྲ\"]\n",
    "\n",
    "ePhulKyangpa10 = [\"ཁ\", \"ག\", \"ཆ\", \"ཇ\", \"ཐ\", \"ད\", \"ཕ\", \"བ\", \"ཚ\", \"ཛ\"]\n",
    "ePhulDogcan9 = [\"ཁྱ\", \"ཁྲ\", \"གྱ\", \"གྲ\", \"དྲ\", \"ཕྲ\", \"ཕྱ\", \"བྱ\", \"བྲ\"]\n",
    "\n",
    "gePhul11 = gePhulKyangpa11\n",
    "bePhul48 = bePhulKyangpa10 + bePhulDogcan7 + bePhulRaGocan11 + bePhulLaGocan2 + bePhulSaGocan10 + bePhulSumtseg6\n",
    "dePhul16 = dePhulKyangpa6 + dePhulDogcan10\n",
    "mePhul15 = mePhulKyangpa11 + mePhulDogcan4\n",
    "ePhul19 = ePhulKyangpa10 + ePhulDogcan9\n",
    "\n",
    "phulyig107 = gePhul11 + bePhul48 + dePhul16 + mePhul15 + ePhul19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jejug10 = [\"\", \"ག\", \"ང\", \"ད\", \"ན\", \"བ\", \"མ\", \"འ\", \"ར\", \"ལ\", \"ས\"]\n",
    "ngonjug5 = [\"\", \"ག\", \"ད\", \"བ\", \"མ\", \"འ\"]\n",
    "yang4 = [\"\", \"ི\", \"ུ\", \"ེ\", \"ོ\"] \n",
    "yangjug1 = [\"\", \"ས\"]\n",
    "yangjugcan4 = [\"ག\", \"ང\", \"བ\", \"མ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syllables = []\n",
    "\n",
    "# [mingzhi+gocan+dogcan] > ngonjug > yang > jejug > yangjug > wazur\n",
    "for stack in kyangTsegDogKun:\n",
    "    ngonjug = \"\"\n",
    "    gocan = \"\"\n",
    "    mingzhi = \"\"\n",
    "    dogcan = \"\"\n",
    "    yang = \"\"\n",
    "    jejug = \"\"\n",
    "    yangjug = \"\"\n",
    "    \n",
    "    # 1. attribute values to the main stack of letter\n",
    "    gocan = all_parts_dict[stack][\"gocan\"]\n",
    "    mingzhi = all_parts_dict[stack][\"mingzhi\"]\n",
    "    dogcan = all_parts_dict[stack][\"dogcan\"]\n",
    "        \n",
    "    for n in ngonjug5:\n",
    "        # 2. attribute the right value to the prefix\n",
    "        if n == \"ག\" and stack in gePhul11:\n",
    "            ngonjug = n\n",
    "        elif n == \"ད\" and stack in dePhul16:\n",
    "            ngonjug = n\n",
    "        elif n == \"བ\" and stack in bePhul48:\n",
    "            ngonjug = n\n",
    "        elif n == \"མ\" and stack in mePhul15:\n",
    "            ngonjug = n\n",
    "        elif n == \"འ\" and stack in ePhul19:\n",
    "            ngonjug = n\n",
    "            \n",
    "        for y in yang4:\n",
    "            # 3. attribute a value to the vowel\n",
    "            yang = y\n",
    "            \n",
    "            for j in jejug10:\n",
    "                # 4. attribute a value to the suffix\n",
    "                jejug = j\n",
    "                \n",
    "                for ya in yangjug1:\n",
    "                    # 5. attribute a value to the post-suffix or not\n",
    "                    if jejug in yangjugcan4:\n",
    "                        yangjug = ya\n",
    "                    \n",
    "                    # 6. adding a achung to cases where there is a prefix, \n",
    "                    #    a main letter but no suffix.\n",
    "                    # །རྐྱང་པ་འཕུལ་བ་འ་ཡི་མཐའ། །དགོས་ཀྱི་གུག་སྐྱེད་ཅན་ལ་མིན།\n",
    "                    if jejug == \"\" and mingzhi != \"\" and ngonjug != \"\" and yang == \"\" and gocan == \"\" and dogcan == \"\":\n",
    "                        jejug = \"འ\"\n",
    "                    \n",
    "                    # 7. removing unnecessary འ\n",
    "                    if jejug == \"འ\":\n",
    "                        if ngonjug == \"\" and gocan == \"\" and dogcan == \"\" and yang == \"\":\n",
    "                            jejug = \"\"\n",
    "                        elif yang != \"\":\n",
    "                            jejug = \"\"\n",
    "                        elif gocan != \"\" or dogcan != \"\":\n",
    "                            jejug = \"\"\n",
    "                        elif gocan != \"\" and dogcan != \"\":\n",
    "                            jejug = \"\"\n",
    "                    \n",
    "                    syllable = ngonjug+ stack  +yang+jejug+yangjug\n",
    "                    parts = {\"ngonjug\": ngonjug, \"gocan\": gocan, \"mingzhi\": mingzhi, \"dogcan\": dogcan, \"wazur\": \"\", \"yang_1\": yang, \"jejug\": jejug, \"yang_2\": \"\", \"yangjug\": yangjug}\n",
    "                    if syllable not in syllables :\n",
    "                        syllables.append((syllable, parts))\n",
    "                    yangjug = \"\"\n",
    "                jejug = \"\"\n",
    "            yang = \"\"\n",
    "\n",
    "# adding exceptions [\"མདྲོན\", \"བགླ\", \"མདྲ\", \"དྭགས\", \"དྭངས\", \"དྭབས\", \"དྭམས\", \"མྭགས\", \"མྭངས\", \"འྭགས\", \"འྭབས\"]\n",
    "migsel = [(\"མདྲོན\" , {\"ngonjug\": \"མ\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"ར\", \"wazur\": \"\", \"yang_1\": \"ོ\", \"jejug\": \"ན\", \"yang_2\": \"\", \"yangjug\": \"\"}), (\"བགླ\" , {\"ngonjug\": \"བ\", \"gocan\": \"\", \"mingzhi\": \"ག\", \"dogcan\": \"ལ\", \"wazur\": \"\", \"yang_1\": \"\", \"jejug\": \"\", \"yang_2\": \"\", \"yangjug\": \"\"}), (\"མདྲ\" , {\"ngonjug\": \"མ\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"ར\", \"wazur\": \"\", \"yang_1\": \"\", \"jejug\": \"\", \"yang_2\": \"\", \"yangjug\": \"\"}), (\"དྭགས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"ག\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"དྭངས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"ང\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"དྭབས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"བ\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"དྭམས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"ད\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"མ\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"མྭགས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"མ\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"ག\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"མྭངས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"མ\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"ང\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"འྭགས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"འ\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"ག\", \"yang_2\": \"\", \"yangjug\": \"ས\"}), (\"འྭབས\" , {\"ngonjug\": \"\", \"gocan\": \"\", \"mingzhi\": \"འ\", \"dogcan\": \"\", \"wazur\": \"ཝ\", \"yang_1\": \"\", \"jejug\": \"བ\", \"yang_2\": \"\", \"yangjug\": \"ས\"})]\n",
    "for m in migsel:\n",
    "    syllables.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-e6dce8da2aa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msyllables_singled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msyl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msyllables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0msyl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msyllables_singled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msyllables_singled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyllables_singled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "syllables_singled = []\n",
    "for syl in syllables:\n",
    "    if syl not in syllables_singled:\n",
    "        syllables_singled.append(syl)\n",
    "print(len(syllables_singled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for nb, s in enumerate(syllables_singled):\n",
    "    if s[1][\"jejug\"] == \"འ\" or s[1][\"jejug\"] == \"\":\n",
    "        #print(s)\n",
    "        print(s[0], end= \"་ \")\n",
    "        count = count + 1\n",
    "print()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_list = []\n",
    "#test= [('ཀི་', {'ngonjug': '', 'yang_2': '', 'jejug': '', 'mingzhi': 'ཀ', 'yangjug': '', 'gocan': '', 'dogcan': '', 'yang_1': 'ི', 'wazur': ''}), ('ཀོའ་', {'ngonjug': '', 'yang_2': '', 'jejug': 'འ', 'mingzhi': 'ཀ', 'yangjug': '', 'gocan': '', 'dogcan': '', 'yang_1': 'ོ', 'wazur': ''}), ('ཀུ་', {'ngonjug': '', 'yang_2': '', 'jejug': '', 'mingzhi': 'ཀ', 'yangjug': '', 'gocan': '', 'dogcan': '', 'yang_1': 'ུ', 'wazur': ''})]\n",
    "for s in syllables_singled:\n",
    "    if s[1][\"jejug\"] == \"འ\":\n",
    "        for y in [\"ི\", \"ོ\", \"ུ\"]:\n",
    "            parts = s[1]\n",
    "            parts[\"yang_2\"] = y\n",
    "            syllable = s[0].split(\"་\")[0]+y+\"་\"\n",
    "            new_list.append((syllable, parts))\n",
    "    if s[1][\"jejug\"] == \"\":\n",
    "        for y in [\"ི\", \"ོ\", \"ུ\"]:\n",
    "            parts = s[1]\n",
    "            parts[\"jejug\"] = \"འ\"\n",
    "            parts[\"yang_2\"] = y \n",
    "            syllable = s[0].split(\"་\")[0]+\"འ\"+y+\"་\"\n",
    "            new_list.append((syllable, parts))\n",
    "\n",
    "for n in new_list:\n",
    "    print(n[0], end=\" \")\n",
    "new_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#searching for a syllable from a character included in it.\n",
    "\n",
    "count = 0\n",
    "for nb, s in enumerate(syllables_singled):\n",
    "    if \"མ\" in s[0]: \n",
    "        print(s[0], end = \"་ \")\n",
    "        count = count + 1\n",
    "print()\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}